<?xml version="1.0" encoding="UTF-8"?>
<tool_instructions>
  <tools>
    <tool>
      <name>firecrawl.firecrawl_scrape</name>
      <description>Scrapes content from a single URL with configurable options.</description>
      <usage>Use when you need to retrieve and analyze the content of a specific webpage.</usage>
      <parameters>
        <parameter name="url" type="string" required="true">The URL to scrape.</parameter>
        <parameter name="formats" type="array" required="false" default="['markdown']">Output format(s). Use ['markdown'] for most cases.</parameter>
        <parameter name="onlyMainContent" type="boolean" required="false" default="true">Focus on main content and filter out navigation, ads, etc.</parameter>
        <parameter name="waitFor" type="number" required="false">Time to wait for JavaScript rendering in ms.</parameter>
        <parameter name="timeout" type="number" required="false" default="30000">Maximum scraping time in ms.</parameter>
        <parameter name="mobile" type="boolean" required="false" default="false">Use mobile viewport if true.</parameter>
        <parameter name="includeTags" type="array" required="false">HTML tags to include (e.g., ["article", "main"]).</parameter>
        <parameter name="excludeTags" type="array" required="false">HTML tags to exclude (e.g., ["nav", "footer"]).</parameter>
      </parameters>
      <example>
        <request>
          {
            "name": "firecrawl.firecrawl_scrape",
            "arguments": {
              "url": "https://www.example.com/article",
              "formats": ["markdown"],
              "onlyMainContent": true
            }
          }
        </request>
      </example>
    </tool>

    <tool>
      <name>firecrawl.firecrawl_batch_scrape</name>
      <description>Scrapes multiple URLs efficiently in parallel with rate limiting.</description>
      <usage>Use when you need to analyze content from multiple webpages at once.</usage>
      <parameters>
        <parameter name="urls" type="array" required="true">Array of URLs to scrape.</parameter>
        <parameter name="options" type="object" required="false">
          Scraping options applied to all URLs. Same options as firecrawl_scrape.
        </parameter>
      </parameters>
      <example>
        <request>
          {
            "name": "firecrawl.firecrawl_batch_scrape",
            "arguments": {
              "urls": [
                "https://example.com/page1",
                "https://example.com/page2"
              ],
              "options": {
                "formats": ["markdown"],
                "onlyMainContent": true
              }
            }
          }
        </request>
      </example>
    </tool>

    <tool>
      <name>firecrawl.firecrawl_check_batch_status</name>
      <description>Checks the status of a batch operation started with firecrawl_batch_scrape.</description>
      <usage>Use after starting a batch scrape to check its progress and get results.</usage>
      <parameters>
        <parameter name="id" type="string" required="true">The batch operation ID to check.</parameter>
      </parameters>
      <example>
        <request>
          {
            "name": "firecrawl.firecrawl_check_batch_status",
            "arguments": {
              "id": "batch_1"
            }
          }
        </request>
      </example>
    </tool>

    <tool>
      <name>firecrawl.firecrawl_search</name>
      <description>Searches the web and optionally extracts content from search results.</description>
      <usage>Use when you need to find current information on any topic. This is often the best first step for research queries.</usage>
      <parameters>
        <parameter name="query" type="string" required="true">The search query.</parameter>
        <parameter name="limit" type="number" required="false" default="5">Maximum number of results.</parameter>
        <parameter name="lang" type="string" required="false" default="en">Language code.</parameter>
        <parameter name="country" type="string" required="false" default="us">Country code.</parameter>
        <parameter name="scrapeOptions" type="object" required="false">
          Options to automatically scrape content from search results.
        </parameter>
      </parameters>
      <example>
        <request>
          {
            "name": "firecrawl.firecrawl_search",
            "arguments": {
              "query": "latest developments in quantum computing",
              "limit": 5,
              "scrapeOptions": {
                "formats": ["markdown"],
                "onlyMainContent": true
              }
            }
          }
        </request>
      </example>
    </tool>

    <tool>
      <name>firecrawl.firecrawl_crawl</name>
      <description>Starts an asynchronous crawl of a website with configurable depth and scope.</description>
      <usage>Use when you need to explore multiple pages within a website, such as documentation or connected articles.</usage>
      <parameters>
        <parameter name="url" type="string" required="true">Starting URL for the crawl.</parameter>
        <parameter name="maxDepth" type="number" required="false" default="2">Maximum link traversal depth.</parameter>
        <parameter name="limit" type="number" required="false" default="100">Maximum number of pages to crawl.</parameter>
        <parameter name="allowExternalLinks" type="boolean" required="false" default="false">Whether to follow links to other domains.</parameter>
        <parameter name="deduplicateSimilarURLs" type="boolean" required="false" default="true">Whether to deduplicate similar URLs.</parameter>
      </parameters>
      <example>
        <request>
          {
            "name": "firecrawl.firecrawl_crawl",
            "arguments": {
              "url": "https://example.com/docs",
              "maxDepth": 2,
              "limit": 50
            }
          }
        </request>
      </example>
    </tool>

    <tool>
      <name>firecrawl.firecrawl_extract</name>
      <description>Extracts structured information from web pages using LLM capabilities.</description>
      <usage>Use when you need to extract specific structured data from webpages, such as product details, contact information, or any pattern-based content.</usage>
      <parameters>
        <parameter name="urls" type="array" required="true">Array of URLs to extract from.</parameter>
        <parameter name="prompt" type="string" required="true">Instructions for what to extract.</parameter>
        <parameter name="systemPrompt" type="string" required="false">System prompt for extraction.</parameter>
        <parameter name="schema" type="object" required="true">JSON Schema defining the structure to extract.</parameter>
        <parameter name="allowExternalLinks" type="boolean" required="false" default="false">Whether to follow external links.</parameter>
        <parameter name="enableWebSearch" type="boolean" required="false" default="false">Whether to allow web search for context.</parameter>
      </parameters>
      <example>
        <request>
          {
            "name": "firecrawl.firecrawl_extract",
            "arguments": {
              "urls": ["https://example.com/product"],
              "prompt": "Extract the product name, price, and key features",
              "schema": {
                "type": "object",
                "properties": {
                  "name": { "type": "string" },
                  "price": { "type": "number" },
                  "features": { "type": "array", "items": { "type": "string" } }
                },
                "required": ["name", "price"]
              }
            }
          }
        </request>
      </example>
    </tool>

    <tool>
      <name>firecrawl.firecrawl_deep_research</name>
      <description>Conducts comprehensive research on a topic using intelligent crawling, search, and analysis.</description>
      <usage>Use for complex research questions that require synthesizing information from multiple sources.</usage>
      <parameters>
        <parameter name="query" type="string" required="true">The research question or topic.</parameter>
        <parameter name="maxDepth" type="number" required="false" default="3">Maximum recursive depth for crawling/search.</parameter>
        <parameter name="timeLimit" type="number" required="false" default="120">Time limit in seconds.</parameter>
        <parameter name="maxUrls" type="number" required="false" default="50">Maximum URLs to analyze.</parameter>
      </parameters>
      <example>
        <request>
          {
            "name": "firecrawl.firecrawl_deep_research",
            "arguments": {
              "query": "How does carbon capture technology work and what are recent advancements?",
              "maxDepth": 3,
              "timeLimit": 180,
              "maxUrls": 30
            }
          }
        </request>
      </example>
    </tool>

    <tool>
      <name>firecrawl.firecrawl_generate_llmstxt</name>
      <description>Generates a standardized llms.txt file for a domain, defining how LLMs should interact with the site.</description>
      <usage>Use when you need to understand the intended interaction guidelines for a website.</usage>
      <parameters>
        <parameter name="url" type="string" required="true">The website's base URL.</parameter>
        <parameter name="maxUrls" type="number" required="false" default="5" limit="5">Maximum URLs to include.</parameter>
        <parameter name="showFullText" type="boolean" required="false" default="true">Whether to include full text.</parameter>
      </parameters>
      <example>
        <request>
          {
            "name": "firecrawl.firecrawl_generate_llmstxt",
            "arguments": {
              "url": "https://example.com",
              "maxUrls": 5,
              "showFullText": false 
            }
          }
        </request>
      </example>
    </tool>
  </tools>
</tool_instructions> 